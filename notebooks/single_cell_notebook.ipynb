{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# MARKDOWN\n",
    "# Voice-Based Cognitive Decline Pattern Detection\n",
    "\n",
    "This notebook demonstrates a comprehensive pipeline for analyzing speech patterns to detect potential cognitive decline indicators. It processes audio samples, extracts linguistic and acoustic features, and applies unsupervised machine learning to identify anomalies.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Objective:** Build a proof-of-concept pipeline that uses raw voice data to detect cognitive stress or decline indicators using NLP and audio feature extraction.\n",
    "\n",
    "**Features Analyzed:**\n",
    "- Pauses per sentence\n",
    "- Hesitation markers (uh, um, etc.)\n",
    "- Word recall issues (compared to baseline text)\n",
    "- Speech rate and pitch variability\n",
    "- Naming task performance\n",
    "- Sentence completion quality\n",
    "\n",
    "**ML Approach:** Unsupervised clustering and anomaly detection to identify abnormal speech patterns.\n",
    "\n",
    "# CODE\n",
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our custom modules\n",
    "from audio_processor import AudioProcessor\n",
    "from transcriber import Transcriber\n",
    "from analyzer import SpeechAnalyzer\n",
    "from word_recall import WordRecallDetector\n",
    "from sentence_completion import SentenceCompletionDetector\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# MARKDOWN\n",
    "## 1. Environment Setup\n",
    "\n",
    "First, we need to set up our environment and initialize the components of our pipeline. This includes:\n",
    "- Audio processor for feature extraction\n",
    "- Transcriber for speech-to-text and linguistic analysis\n",
    "- Speech analyzer for ML-based pattern detection\n",
    "\n",
    "# CODE\n",
    "# Set up environment variables (if not already set)\n",
    "import os\n",
    "# Uncomment and set your Groq API key if not set in environment\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "# Get Groq API key from environment\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable is not set. Please set it before running the notebook.\")\n",
    "\n",
    "# Initialize components\n",
    "audio_processor = AudioProcessor()\n",
    "transcriber = Transcriber(groq_api_key)\n",
    "analyzer = SpeechAnalyzer()\n",
    "\n",
    "# Set default naming task targets\n",
    "transcriber.set_naming_targets([\n",
    "    \"apple\", \"banana\", \"car\", \"dog\", \"elephant\",\n",
    "    \"flower\", \"guitar\", \"house\", \"ice cream\", \"jacket\"\n",
    "])\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "\n",
    "# MARKDOWN\n",
    "## 2. Load Audio Files\n",
    "\n",
    "We'll load audio files from the `data/audio` directory. For this analysis, we need 5-10 audio samples.\n",
    "\n",
    "# CODE\n",
    "# Get list of audio files (both WAV and MP3)\n",
    "audio_files = glob.glob('../data/audio/*.wav') + glob.glob('../data/audio/*.mp3')\n",
    "print(f\"Found {len(audio_files)} audio files:\")\n",
    "\n",
    "# Display available audio files\n",
    "for i, file in enumerate(audio_files):\n",
    "    print(f\"{i+1}. {os.path.basename(file)}\")\n",
    "\n",
    "# Check if we have enough files\n",
    "if len(audio_files) < 5:\n",
    "    print(\"\\nWARNING: For a comprehensive analysis, it's recommended to have at least 5 audio samples.\")\n",
    "elif len(audio_files) > 10:\n",
    "    print(\"\\nNote: You have more than 10 audio samples. This is fine, but processing might take longer.\")\n",
    "\n",
    "# MARKDOWN\n",
    "## 3. Audio Preprocessing and Feature Extraction\n",
    "\n",
    "For each audio file, we'll:\n",
    "1. Load and preprocess the audio (resample, normalize)\n",
    "2. Extract acoustic features (pauses, pitch statistics)\n",
    "3. Transcribe the speech\n",
    "4. Analyze the transcript for linguistic features\n",
    "\n",
    "# CODE\n",
    "# Define baseline text for word recall analysis (optional)\n",
    "baseline_text = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. She sells seashells by the seashore.\n",
    "The rain in Spain stays mainly in the plain. How much wood would a woodchuck chuck.\n",
    "\"\"\"\n",
    "\n",
    "# Process each file\n",
    "features_list = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    print(f\"\\nProcessing {os.path.basename(audio_file)}...\")\n",
    "    \n",
    "    # Load and preprocess audio\n",
    "    y, sr = audio_processor.load_and_preprocess(audio_file)\n",
    "    \n",
    "    # Extract acoustic features\n",
    "    pauses = audio_processor.extract_pauses(y, sr)\n",
    "    pitch_stats = audio_processor.compute_pitch_stats(y, sr)\n",
    "    \n",
    "    # Play a short sample of the audio (first 3 seconds)\n",
    "    print(\"Audio sample (first 3 seconds):\")\n",
    "    sample_length = min(3 * sr, len(y))\n",
    "    display(Audio(y[:sample_length], rate=sr))\n",
    "    \n",
    "    # Transcribe\n",
    "    transcript = transcriber.transcribe(audio_file)\n",
    "    print(f\"Transcript: {transcript}\")\n",
    "    \n",
    "    # Analyze transcript\n",
    "    transcript_analysis = transcriber.analyze_transcript(transcript, baseline_text)\n",
    "    \n",
    "    # Compute speech rate\n",
    "    duration = len(y) / sr\n",
    "    speech_rate = audio_processor.compute_speech_rate(\n",
    "        transcript_analysis['word_count'], \n",
    "        duration\n",
    "    )\n",
    "    \n",
    "    # Calculate cognitive risk score\n",
    "    risk_score = transcriber.get_cognitive_risk_score(transcript_analysis)\n",
    "    \n",
    "    # Compile features\n",
    "    features = {\n",
    "        'file': os.path.basename(audio_file),\n",
    "        'transcript': transcript,\n",
    "        'pause_count': len(pauses),\n",
    "        'hesitation_count': transcript_analysis['hesitation_count'],\n",
    "        'speech_rate': speech_rate,\n",
    "        'pitch_stats': pitch_stats,\n",
    "        'word_recall': transcript_analysis.get('word_recall', {}),\n",
    "        'naming_task': transcript_analysis.get('naming_task', {}),\n",
    "        'sentence_completion': transcript_analysis.get('sentence_completion', {}),\n",
    "        'completion_score': transcript_analysis.get('completion_score', 0),\n",
    "        'cognitive_risk_score': risk_score,\n",
    "        'cognitive_assessment': {\n",
    "            'risk_level': 'Low' if risk_score > 0.7 else 'Medium' if risk_score > 0.4 else 'High',\n",
    "            'indicators': {\n",
    "                'hesitation_frequency': 'Normal' if transcript_analysis.get('hesitation_rate', 0) < 0.1 else 'Elevated',\n",
    "                'speech_rate': 'Normal' if 80 <= speech_rate <= 160 else 'Abnormal',\n",
    "                'sentence_structure': 'Normal' if transcript_analysis.get('completion_score', 1) > 0.8 else 'Impaired'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    features_list.append(features)\n",
    "    print(f\"Processed {os.path.basename(audio_file)} - Risk Score: {risk_score:.2f} ({features['cognitive_assessment']['risk_level']} risk)\")\n",
    "\n",
    "print(\"\\nFeature extraction complete!\")\n",
    "\n",
    "# MARKDOWN\n",
    "## 4. Feature Analysis and Visualization\n",
    "\n",
    "Now we'll analyze the extracted features to identify patterns and potential indicators of cognitive decline.\n",
    "\n",
    "# CODE\n",
    "# Create a DataFrame with basic features for easier analysis\n",
    "basic_features_df = pd.DataFrame([\n",
    "    {\n",
    "        'File': f['file'],\n",
    "        'Pauses': f['pause_count'],\n",
    "        'Hesitations': f['hesitation_count'],\n",
    "        'Speech Rate': f['speech_rate'],\n",
    "        'Pitch Mean': f['pitch_stats']['pitch_mean'],\n",
    "        'Pitch Std': f['pitch_stats']['pitch_std'],\n",
    "        'Completion Score': f['completion_score'],\n",
    "        'Risk Score': f['cognitive_risk_score'],\n",
    "        'Risk Level': f['cognitive_assessment']['risk_level']\n",
    "    }\n",
    "    for f in features_list\n",
    "])\n",
    "\n",
    "# Display the basic features\n",
    "print(\"Basic Speech Features:\")\n",
    "basic_features_df\n",
    "\n",
    "# Visualize key metrics\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot speech rate\n",
    "axs[0, 0].bar(basic_features_df['File'], basic_features_df['Speech Rate'], color='skyblue')\n",
    "axs[0, 0].set_title('Speech Rate (words/min)')\n",
    "axs[0, 0].set_ylabel('Words per minute')\n",
    "axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot pause count\n",
    "axs[0, 1].bar(basic_features_df['File'], basic_features_df['Pauses'], color='lightgreen')\n",
    "axs[0, 1].set_title('Pause Count')\n",
    "axs[0, 1].set_ylabel('Number of pauses')\n",
    "axs[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot hesitation count\n",
    "axs[1, 0].bar(basic_features_df['File'], basic_features_df['Hesitations'], color='salmon')\n",
    "axs[1, 0].set_title('Hesitation Markers')\n",
    "axs[1, 0].set_ylabel('Number of hesitations')\n",
    "axs[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot risk score\n",
    "colors = ['green' if level == 'Low' else 'orange' if level == 'Medium' else 'red' \n",
    "          for level in basic_features_df['Risk Level']]\n",
    "axs[1, 1].bar(basic_features_df['File'], basic_features_df['Risk Score'], color=colors)\n",
    "axs[1, 1].set_title('Cognitive Risk Score (higher is better)')\n",
    "axs[1, 1].set_ylabel('Score (0-1)')\n",
    "axs[1, 1].set_ylim(0, 1)\n",
    "axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MARKDOWN\n",
    "## 5. Unsupervised Machine Learning Analysis\n",
    "\n",
    "We'll now apply unsupervised machine learning techniques to identify patterns and anomalies in the speech data.\n",
    "\n",
    "# CODE\n",
    "# Prepare feature matrix for ML analysis\n",
    "feature_matrix = analyzer.prepare_features(features_list)\n",
    "\n",
    "# Perform anomaly detection and clustering\n",
    "labels, anomaly_scores = analyzer.fit_predict(feature_matrix)\n",
    "\n",
    "# Add ML results to our dataframe\n",
    "basic_features_df['Cluster'] = labels\n",
    "basic_features_df['Anomaly Score'] = anomaly_scores\n",
    "basic_features_df['Is Anomaly'] = labels == -1\n",
    "\n",
    "# Display updated dataframe with ML results\n",
    "print(\"Speech Features with ML Analysis:\")\n",
    "basic_features_df\n",
    "\n",
    "# Create visualizations of the ML results\n",
    "pca_fig, tsne_fig = analyzer.visualize_results(feature_matrix, labels)\n",
    "\n",
    "# Display PCA visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(pca_fig)\n",
    "plt.title(\"PCA Visualization of Speech Features\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Display t-SNE visualization\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(tsne_fig)\n",
    "plt.title(\"t-SNE Visualization of Speech Features\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MARKDOWN\n",
    "## 6. Correlation Analysis\n",
    "\n",
    "Let's examine the correlations between different speech features to identify which features are most predictive of cognitive risk.\n",
    "\n",
    "# CODE\n",
    "# Select numerical features for correlation analysis\n",
    "corr_features = basic_features_df[['Pauses', 'Hesitations', 'Speech Rate', \n",
    "                                  'Pitch Mean', 'Pitch Std', 'Completion Score', \n",
    "                                  'Risk Score', 'Anomaly Score']]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = corr_features.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.2f')\n",
    "plt.title('Correlation Between Speech Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MARKDOWN\n",
    "## 7. Batch Analysis Summary\n",
    "\n",
    "Now we'll generate a comprehensive summary of our analysis across all audio samples.\n",
    "\n",
    "# CODE\n",
    "# Perform batch analysis\n",
    "batch_analysis = analyzer.analyze_batch(features_list)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Sample Count: {batch_analysis['sample_count']}\")\n",
    "print(f\"Anomaly Count: {batch_analysis['anomaly_count']}\")\n",
    "print(f\"Cluster Count: {batch_analysis['cluster_count']}\")\n",
    "print(f\"Average Anomaly Score: {batch_analysis['avg_anomaly_score']:.2f}\")\n",
    "print(f\"Average Speech Rate: {batch_analysis['avg_speech_rate']:.2f} words/min\")\n",
    "print(f\"Average Pause Count: {batch_analysis['avg_pause_count']:.2f}\")\n",
    "print(f\"Average Hesitation Count: {batch_analysis['avg_hesitation_count']:.2f}\")\n",
    "print(f\"Average Cognitive Risk Score: {batch_analysis['avg_cognitive_risk_score']:.2f}\")\n",
    "\n",
    "# Identify most insightful features\n",
    "feature_importance = corr_matrix['Risk Score'].abs().sort_values(ascending=False)\n",
    "print(\"\\nFeature Importance (correlation with Risk Score):\")\n",
    "for feature, importance in feature_importance.items():\n",
    "    if feature != 'Risk Score':\n",
    "        print(f\"- {feature}: {importance:.2f}\")\n",
    "\n",
    "# MARKDOWN\n",
    "## 8. Conclusions and Next Steps\n",
    "\n",
    "Based on our analysis, we can draw the following conclusions:\n",
    "\n",
    "1. **Most Insightful Features:**\n",
    "   - [Fill in based on your results]\n",
    "   - [e.g., \"Speech rate showed the strongest correlation with cognitive risk scores\"]\n",
    "\n",
    "2. **ML Methods Used:**\n",
    "   - DBSCAN clustering for identifying groups of similar speech patterns\n",
    "   - Anomaly detection for identifying outliers that may indicate cognitive concerns\n",
    "   - Dimensionality reduction (PCA and t-SNE) for visualization\n",
    "\n",
    "3. **Potential Next Steps:**\n",
    "   - Collect larger dataset with confirmed cognitive condition samples\n",
    "   - Implement supervised learning with labeled data\n",
    "   - Refine feature extraction for better sensitivity\n",
    "   - Conduct clinical validation studies\n",
    "\n",
    "This proof-of-concept demonstrates the potential of speech analysis for cognitive assessment, but further development and validation would be needed for clinical applications.\n",
    "\n",
    "# CODE\n",
    "# Export results to CSV for further analysis\n",
    "basic_features_df.to_csv('../data/speech_analysis_results.csv', index=False)\n",
    "print(\"Results exported to '../data/speech_analysis_results.csv'\")\n",
    "\n",
    "# Generate a simple HTML report\n",
    "from IPython.display import HTML\n",
    "\n",
    "html_report = f\"\"\"\n",
    "<h1>Speech Analysis Report</h1>\n",
    "<p>Analysis of {len(features_list)} audio samples</p>\n",
    "\n",
    "<h2>Summary Statistics</h2>\n",
    "<ul>\n",
    "    <li>Sample Count: {batch_analysis['sample_count']}</li>\n",
    "    <li>Anomaly Count: {batch_analysis['anomaly_count']}</li>\n",
    "    <li>Average Risk Score: {batch_analysis['avg_cognitive_risk_score']:.2f}</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Individual Sample Results</h2>\n",
    "<table border=\"1\">\n",
    "    <tr>\n",
    "        <th>File</th>\n",
    "        <th>Risk Score</th>\n",
    "        <th>Risk Level</th>\n",
    "        <th>Anomaly</th>\n",
    "    </tr>\n",
    "\"\"\"\n",
    "\n",
    "for _, row in basic_features_df.iterrows():\n",
    "    color = \"green\" if row['Risk Level'] == \"Low\" else \"orange\" if row['Risk Level'] == \"Medium\" else \"red\"\n",
    "    html_report += f\"\"\"\n",
    "    <tr>\n",
    "        <td>{row['File']}</td>\n",
    "        <td>{row['Risk Score']:.2f}</td>\n",
    "        <td style=\"color:{color}\">{row['Risk Level']}</td>\n",
    "        <td>{\"Yes\" if row['Is Anomaly'] else \"No\"}</td>\n",
    "    </tr>\n",
    "    \"\"\"\n",
    "\n",
    "html_report += \"\"\"\n",
    "</table>\n",
    "<p>This report was generated automatically by the Speech Analysis Pipeline.</p>\n",
    "\"\"\"\n",
    "\n",
    "HTML(html_report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
